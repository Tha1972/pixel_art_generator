{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84914703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from noise_scheduler import LinearNoiseScheduler\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eedf39a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Time embeddings\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, 256),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(256, 256),\n",
    "        )\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.GroupNorm(8, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.GroupNorm(8, 64),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.down1 = nn.Conv2d(64, 64, 4, stride=2, padding=1)   # 16 → 8\n",
    "\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.GroupNorm(8, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.GroupNorm(8, 128),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.down2 = nn.Conv2d(128, 128, 4, stride=2, padding=1) # 8 → 4\n",
    "\n",
    "        # Bottleneck\n",
    "        self.mid = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.GroupNorm(8, 256),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.GroupNorm(8, 256),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode=\"nearest\")   # 4 → 8\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(256 + 128, 128, 3, padding=1),\n",
    "            nn.GroupNorm(8, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.GroupNorm(8, 128),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode=\"nearest\")   # 8 → 16\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(128 + 64, 64, 3, padding=1),\n",
    "            nn.GroupNorm(8, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.GroupNorm(8, 64),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        # Output\n",
    "        self.out = nn.Conv2d(64, 3, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Timestep embedding\n",
    "        t = t.float().unsqueeze(1)\n",
    "        t_emb = self.time_mlp(t)\n",
    "\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e1 = e1 + t_emb[:, :64, None, None]\n",
    "\n",
    "        x = self.down1(e1)\n",
    "\n",
    "        e2 = self.enc2(x)\n",
    "        e2 = e2 + t_emb[:, :128, None, None]\n",
    "\n",
    "        x = self.down2(e2)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.mid(x)\n",
    "        x = x + t_emb[:, :256, None, None]\n",
    "\n",
    "        # Decoder\n",
    "        x = self.up1(x)\n",
    "        x = torch.cat([x, e2], dim=1)\n",
    "        x = self.dec1(x)\n",
    "        x = x + t_emb[:, :128, None, None]\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x = torch.cat([x, e1], dim=1)\n",
    "        x = self.dec2(x)\n",
    "        x = x + t_emb[:, :64, None, None]\n",
    "\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20d30af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab46a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"data/images/images\"\n",
    "image_paths = [\n",
    "    os.path.join(image_dir, f).split(\"\\\\\")[1].split(\".\")[0]\n",
    "    for f in os.listdir(image_dir)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7be2ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_label_paths = df[df[\"Label\"] == \"[1. 0. 0. 0. 0.]\"][\"Image Path\"].tolist()\n",
    "# first_label_paths = df[\"Image Path\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "0add7c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_paths = [i.split(\"/\")[2].split(\".\")[0] for i in first_label_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "6db22e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [\n",
    "            os.path.join(image_dir, f).split(\"\\\\\")[1].split(\".\")[0]\n",
    "            for f in os.listdir(image_dir)\n",
    "            if os.path.join(image_dir, f).split(\"\\\\\")[1].split(\".\")[0] in filtered_paths\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a3e9426a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "ef8d2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_paths = [\n",
    "            os.path.join(image_dir, f)\n",
    "            for f in os.listdir(image_dir)\n",
    "            if os.path.join(image_dir, f).split(\"\\\\\")[1].split(\".\")[0] in filtered_paths\n",
    "        ]\n",
    "\n",
    "        print(len(self.image_paths))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        img = np.array(img)\n",
    "\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0\n",
    "        img = img * 2 - 1         \n",
    "\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "626f420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_sample(x0, t, scheduler):\n",
    "    noise = torch.randn_like(x0)\n",
    "\n",
    "    sqrt_ab = scheduler.sqrt_alpha_cum_prod[t][:, None, None, None]\n",
    "    sqrt_omab = scheduler.sqrt_one_minus_alpha_cum_prod[t][:, None, None, None]\n",
    "\n",
    "    x_t = sqrt_ab * x0 + sqrt_omab * noise\n",
    "    return x_t, noise\n",
    "\n",
    "def diffusion_loss(model, x0, scheduler):\n",
    "    B = x0.size(0)\n",
    "    device = x0.device\n",
    "\n",
    "    t = torch.randint(0, scheduler.num_timesteps, (B,), device=device)\n",
    "\n",
    "    x_t, noise = q_sample(x0, t, scheduler)\n",
    "    pred_noise = model(x_t, t)\n",
    "\n",
    "    return F.mse_loss(pred_noise, noise)\n",
    "\n",
    "def train_diffusion(\n",
    "    model,\n",
    "    dataloader,\n",
    "    epochs,\n",
    "    lr=1e-4,\n",
    "    num_timesteps=100,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    scheduler = LinearNoiseScheduler(\n",
    "        num_timesteps=num_timesteps,\n",
    "        beta_start=1e-4,\n",
    "        beta_end=0.02\n",
    "        )\n",
    "    \n",
    "    scheduler.betas = scheduler.betas.to(device)\n",
    "    scheduler.alphas = scheduler.alphas.to(device)\n",
    "    scheduler.alpha_cum_prod = scheduler.alpha_cum_prod.to(device)\n",
    "    scheduler.sqrt_alpha_cum_prod = scheduler.sqrt_alpha_cum_prod.to(device)\n",
    "    scheduler.sqrt_one_minus_alpha_cum_prod = scheduler.sqrt_one_minus_alpha_cum_prod.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for i, images in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "\n",
    "            loss = diffusion_loss(model, images, scheduler)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {avg_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "6589621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "Starting train\n",
      "Epoch [1/50] | Loss: 1.651633\n",
      "Epoch [2/50] | Loss: 0.801794\n",
      "Epoch [3/50] | Loss: 0.348179\n",
      "Epoch [4/50] | Loss: 0.229085\n",
      "Epoch [5/50] | Loss: 0.205781\n",
      "Epoch [6/50] | Loss: 0.183497\n",
      "Epoch [7/50] | Loss: 0.165859\n",
      "Epoch [8/50] | Loss: 0.148444\n",
      "Epoch [9/50] | Loss: 0.129964\n",
      "Epoch [10/50] | Loss: 0.111513\n",
      "Epoch [11/50] | Loss: 1.271382\n",
      "Epoch [12/50] | Loss: 1.000989\n",
      "Epoch [13/50] | Loss: 0.990248\n",
      "Epoch [14/50] | Loss: 0.476331\n",
      "Epoch [15/50] | Loss: 0.119735\n",
      "Epoch [16/50] | Loss: 0.091481\n",
      "Epoch [17/50] | Loss: 0.082026\n",
      "Epoch [18/50] | Loss: 0.077078\n",
      "Epoch [19/50] | Loss: 0.069483\n",
      "Epoch [20/50] | Loss: 0.065661\n",
      "Epoch [21/50] | Loss: 0.063458\n",
      "Epoch [22/50] | Loss: 0.453069\n",
      "Epoch [23/50] | Loss: 0.119013\n",
      "Epoch [24/50] | Loss: 0.063536\n",
      "Epoch [25/50] | Loss: 0.059934\n",
      "Epoch [26/50] | Loss: 0.069184\n",
      "Epoch [27/50] | Loss: 0.052226\n",
      "Epoch [28/50] | Loss: 0.053096\n",
      "Epoch [29/50] | Loss: 0.050326\n",
      "Epoch [30/50] | Loss: 0.049867\n",
      "Epoch [31/50] | Loss: 0.211270\n",
      "Epoch [32/50] | Loss: 0.055812\n",
      "Epoch [33/50] | Loss: 0.045135\n",
      "Epoch [34/50] | Loss: 0.043982\n",
      "Epoch [35/50] | Loss: 0.047252\n",
      "Epoch [36/50] | Loss: 0.043475\n",
      "Epoch [37/50] | Loss: 0.043457\n",
      "Epoch [38/50] | Loss: 0.042983\n",
      "Epoch [39/50] | Loss: 0.043902\n",
      "Epoch [40/50] | Loss: 0.190774\n",
      "Epoch [41/50] | Loss: 0.045202\n",
      "Epoch [42/50] | Loss: 0.039929\n",
      "Epoch [43/50] | Loss: 0.038763\n",
      "Epoch [44/50] | Loss: 0.036735\n",
      "Epoch [45/50] | Loss: 0.036876\n",
      "Epoch [46/50] | Loss: 0.039409\n",
      "Epoch [47/50] | Loss: 0.038372\n",
      "Epoch [48/50] | Loss: 0.036496\n",
      "Epoch [49/50] | Loss: 0.037418\n",
      "Epoch [50/50] | Loss: 0.038465\n"
     ]
    }
   ],
   "source": [
    "model = UNet()\n",
    "\n",
    "dataset = ImageFolderDataset(\"data/images/images\")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print(\"Starting train\")\n",
    "train_diffusion(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    epochs=50,\n",
    "    lr=1e-3,\n",
    "    num_timesteps=75,\n",
    "    device=\"cuda\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "b08c51e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(\n",
    "    model,\n",
    "    scheduler,\n",
    "    generated_image=None,\n",
    "    image_size=16,\n",
    "    device=\"mps\",\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    if generated_image is not None:\n",
    "        x = generated_image.to(device)\n",
    "    else:\n",
    "        x = torch.randn(1, 3, image_size, image_size, device=device)\n",
    "\n",
    "    for t in reversed(range(scheduler.num_timesteps)):\n",
    "        t_tensor = torch.tensor([t], device=device)\n",
    "\n",
    "        pred_noise = model(x, t_tensor)\n",
    "\n",
    "        alpha = scheduler.alphas[t]\n",
    "        alpha_bar = scheduler.alpha_cum_prod[t]\n",
    "        beta = scheduler.betas[t]\n",
    "\n",
    "        x = (1 / torch.sqrt(alpha)) * (\n",
    "            x - (beta / torch.sqrt(1 - alpha_bar)) * pred_noise\n",
    "        )\n",
    "\n",
    "        if t > 0:\n",
    "            noise = torch.randn_like(x)\n",
    "            # noise = noise * 1.2\n",
    "            x = x + torch.sqrt(beta) * noise\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "a1402fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = LinearNoiseScheduler(\n",
    "    num_timesteps=100,\n",
    "    beta_start=1e-4,\n",
    "    beta_end=0.02\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "2e68d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"  # or cuda\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "sampled = sample(model, scheduler, image_size=16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "85caedd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = sampled.squeeze(0)\n",
    "img = (img + 1) / 2         \n",
    "img = img.clamp(0, 1)\n",
    "img = img.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c837d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a2ee9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixel_art_generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
